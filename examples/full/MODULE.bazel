module(
    name = "full_example",
    version = "0.0.0",
)

bazel_dep(
    name = "rules_s3",
    version = "0.0.0",
)
local_path_override(
    module_name = "rules_s3",
    path = "../..",
)

bazel_dep(
    name = "tweag-credential-helper",
    version = "0.0.3",
    dev_dependency = True,
)

bazel_dep(
    name = "bazel_skylib",
    version = "1.7.1",
)
bazel_dep(
    name = "platforms",
    version = "0.0.10",
)

# Fetching individual blobs works just like `http_file`

s3_file = use_repo_rule("@rules_s3//s3:repo_rules.bzl", "s3_file")

s3_file(
    name = "k8s_1_30_2_release_notes",
    sha256 = "e879f76b7bac8effe4cc53bce034f258ce15b2825f3018c7078f25e832c3feb8",
    url = "s3://malte-s3-public-test/release/v1.30.2/release-notes.json",
    endpoint = "s3.eu-north-1.amazonaws.com",
)

s3_file(
    name = "k8s_1_30_3_release_notes",
    integrity = "sha256-kJtiyAtc4fUHXJyTAfeWc3J6d8RqUl8SxHUzcFNr/iw=",
    url = "s3://malte-s3-public-test/release/v1.30.3/release-notes.json",
    endpoint = "s3.eu-north-1.amazonaws.com",
)

# Fetching an archive works just like `http_archive`

s3_archive = use_repo_rule("@rules_s3//s3:repo_rules.bzl", "s3_archive")

s3_archive(
    name = "kubernetes_1_30_3",
    build_file_content = """exports_files(glob(["**"]))""",
    integrity = "sha256-9x9WRt4Xw8n3IgE9T1PlChVoInD1YXrAYdQw6moWAM0=",
    strip_prefix = "kubernetes",
    url = "s3://malte-s3-public-test/release/v1.30.3/kubernetes.tar.gz",
    endpoint = "s3.eu-north-1.amazonaws.com",
)

# If you want to fetch a large number of objects from a bucket, you can use a JSON lockfile

s3_bucket = use_extension("@rules_s3//s3:extensions.bzl", "s3_bucket")
s3_bucket.from_file(
    name = "kubectl_binaries",
    bucket = "malte-s3-public-test",
    endpoint = "s3.eu-north-1.amazonaws.com",
    lockfile = "//:s3_lock.json",
)

# If needed, you can specify how the data should be fetched:
#  - symlink: lazy loading with a hub repo consisting of symlinks to blob repos
#  - alias: lazy loading with a hub repo consisting of alias targets to the blob repos
#  - copy: lazy loading with full file copies of blob contents
#  - eager: all blobs are eagerly fetched into one repo

s3_bucket.from_file(
    name = "symlink_hub_repo",
    bucket = "malte-s3-public-test",
    endpoint = "s3.eu-north-1.amazonaws.com",
    lockfile = "//:s3_lock.json",
    method = "symlink",
)
s3_bucket.from_file(
    name = "alias_hub_repo",
    bucket = "malte-s3-public-test",
    endpoint = "s3.eu-north-1.amazonaws.com",
    lockfile = "//:s3_lock.json",
    method = "alias",
)
s3_bucket.from_file(
    name = "copy_hub_repo",
    bucket = "malte-s3-public-test",
    endpoint = "s3.eu-north-1.amazonaws.com",
    lockfile = "//:s3_lock.json",
    method = "copy",
)
s3_bucket.from_file(
    name = "eager_repo",
    bucket = "malte-s3-public-test",
    endpoint = "s3.eu-north-1.amazonaws.com",
    lockfile = "//:s3_lock.json",
    method = "eager",
)
use_repo(s3_bucket, "alias_hub_repo", "copy_hub_repo", "eager_repo", "kubectl_binaries", "symlink_hub_repo")
